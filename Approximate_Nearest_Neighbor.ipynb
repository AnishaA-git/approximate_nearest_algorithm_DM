{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Approximate_Nearest_Neighbor.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyObPlHYBUHyjVEO6ScTQpGZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnishaA-git/approximate_nearest_algorithm_DM/blob/master/Approximate_Nearest_Neighbor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RH9wJjqEuud"
      },
      "source": [
        "# Assignment: Approximate Nearest Neighbor\n",
        "\n",
        "Steps to follow and complete this assignment:\n",
        "\n",
        "1. Select a dataset which has train, test data, item_features and item_feature_labels.\n",
        "2. Or create from \"lightfm\" library.\n",
        "3. Train the data and test the data using LightFM Model.\n",
        "4. Save the Model Item_embeddings into vector.\n",
        "5. Pickle the data.\n",
        "6. Load the data.\n",
        "7. Use different Algorithms as mentioned in the assignment.\n",
        "\n",
        "\n",
        "Reference: https://making.lyst.com/lightfm/docs/datasets.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIB5p8O15Cxn",
        "outputId": "ac1cab11-8781-4190-afe5-27e322ec5e14"
      },
      "source": [
        "!pip install lightfm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightfm in /usr/local/lib/python3.7/dist-packages (1.16)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from lightfm) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2021.10.8)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightfm) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightfm) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCrKa-8b46dO"
      },
      "source": [
        "from lightfm import LightFM\n",
        "from lightfm.datasets import fetch_stackexchange\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVnMENg0HlQv"
      },
      "source": [
        "# Import Data of StackExchange"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kSJog-GL5_I"
      },
      "source": [
        "Fetch a dataset from the **StackExchange network**.\n",
        "\n",
        "The datasets contain users answering questions: an interaction is defined as a user answering a given question.\n",
        "\n",
        "The following datasets from the StackExchange network are available:\n",
        "\n",
        "1. **CrossValidated**: From stats.stackexchange.com. Approximately 9000 users, 72000 questions, and 70000 answers.\n",
        "2. **StackOverflow**: From stackoverflow.stackexchange.com. Approximately 1.3M users, 11M questions, and 18M answers.\n",
        "\n",
        "I tried using both but the StackOverflow dataset is huge and thus takes a lot of time for further computation and processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OTazyJI5M8b"
      },
      "source": [
        "stackexchange = fetch_stackexchange('crossvalidated')\n",
        "train = stackexchange['train']\n",
        "test = stackexchange['test']\n",
        "\n",
        "model = LightFM(learning_rate=0.05, loss='warp', no_components=64, item_alpha=0.001)\n",
        "model.fit_partial(train, item_features = stackexchange['item_features'], epochs=20 )\n",
        "\n",
        "item_vectors = stackexchange['item_features'] * model.item_embeddings"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-egXRfqbHsdA"
      },
      "source": [
        "# Dump and create Pickle file of the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCitNR4Y8ZiQ"
      },
      "source": [
        "with open('stackexchange.pickle', 'wb') as f:\n",
        "    pickle.dump({\"name\": stackexchange['item_feature_labels'], \"vector\": item_vectors}, f)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM_VY5cK8byd",
        "outputId": "363aca13-f8b7-49a4-994b-f41a474684c6"
      },
      "source": [
        "def load_data():\n",
        "    with open('stackexchange.pickle', 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data\n",
        "\n",
        "data = load_data()\n",
        "data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': array(['question_id:0', 'question_id:1', 'question_id:2', ...,\n",
              "        'question_id:72357', 'question_id:72358', 'question_id:72359'],\n",
              "       dtype='<U17'),\n",
              " 'vector': array([[-5.3533729e-02, -5.6464355e-02, -8.1374869e-02, ...,\n",
              "         -9.6894421e-02,  5.7313439e-02, -1.6908595e-02],\n",
              "        [-6.6331118e-02, -6.5165102e-02, -5.5008505e-02, ...,\n",
              "         -1.6171990e-01,  5.1249313e-05, -4.6256021e-02],\n",
              "        [ 1.4410098e-02,  5.5407797e-04, -7.0389472e-02, ...,\n",
              "          6.3761450e-02,  6.2974453e-02,  3.7036315e-02],\n",
              "        ...,\n",
              "        [ 9.7188018e-03, -4.5543662e-03,  1.9512522e-03, ...,\n",
              "         -1.0468926e-02,  7.3954579e-03,  9.1926325e-03],\n",
              "        [ 1.7524811e-02,  9.5676677e-03, -1.6021287e-02, ...,\n",
              "         -1.5368313e-02,  2.6251541e-02,  8.5461931e-03],\n",
              "        [ 2.9871691e-02, -1.2285559e-01, -1.0679848e-02, ...,\n",
              "         -8.9717414e-03, -2.3016008e-02,  2.9397048e-02]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nzvufDL8r98",
        "outputId": "43ecc36e-faf8-4719-f199-9679deb37d78"
      },
      "source": [
        "!pip install faiss-gpu\n",
        "import faiss"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.7/dist-packages (1.7.1.post2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbxZrP5VHzGD"
      },
      "source": [
        "# LSH: Locality Sensitive Hashing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teUcdIZ583RQ"
      },
      "source": [
        "class LSHIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimension = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels    \n",
        "   \n",
        "    def build(self, num_bits=8):\n",
        "        self.index = faiss.IndexLSH(self.dimension, num_bits)\n",
        "        self.index.add(self.vectors)\n",
        "        \n",
        "    def query(self, vectors, k=10):\n",
        "        distances, indices = self.index.search(vectors, k) \n",
        "        return [self.labels[i] for i in indices[0]]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_fZCyaX85CA"
      },
      "source": [
        "index = LSHIndex(data[\"vector\"], data[\"name\"])\n",
        "index.build()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_GlydXr86xT",
        "outputId": "e6bc13af-4245-4b2a-b2a9-e92fd91d669f"
      },
      "source": [
        "stack_vector, stack_name = data['vector'][90:91], data['name'][90]\n",
        "simlar_stack_questions = '\\n* '.join(index.query(stack_vector))\n",
        "print(f\"The most similar staxk to {stack_name} are:\\n* {simlar_stack_questions}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most similar staxk to question_id:90 are:\n",
            "* question_id:320\n",
            "* question_id:90\n",
            "* question_id:607\n",
            "* question_id:243\n",
            "* question_id:608\n",
            "* question_id:938\n",
            "* question_id:1015\n",
            "* question_id:1024\n",
            "* question_id:304\n",
            "* question_id:172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdINFQToIFx-"
      },
      "source": [
        "# Exhaustive Search using Faiss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbdm5t5J8ewS"
      },
      "source": [
        "class ExhaustiveIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimension = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels    \n",
        "   \n",
        "    def build(self):\n",
        "        self.index = faiss.IndexFlatL2(self.dimension,)\n",
        "        self.index.add(self.vectors)\n",
        "        \n",
        "    def query(self, vectors, k=10):\n",
        "        distances, indices = self.index.search(vectors, k) \n",
        "        return [self.labels[i] for i in indices[0]]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMiVoTnR8hIj"
      },
      "source": [
        "index = ExhaustiveIndex(data[\"vector\"], data[\"name\"])\n",
        "index.build()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClCSQLL680rb",
        "outputId": "3b119bd2-126d-4674-921e-c313ef23b34d"
      },
      "source": [
        "stack_vector, stack_name = data['vector'][90:91], data['name'][90]\n",
        "simlar_stack_questions = '\\n* '.join(index.query(stack_vector))\n",
        "print(f\"The most similar staxk to {stack_name} are:\\n* {simlar_stack_questions}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most similar staxk to question_id:90 are:\n",
            "* question_id:90\n",
            "* question_id:88\n",
            "* question_id:159\n",
            "* question_id:9159\n",
            "* question_id:14515\n",
            "* question_id:3\n",
            "* question_id:3752\n",
            "* question_id:5197\n",
            "* question_id:16477\n",
            "* question_id:6280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ekn98r2kII7N"
      },
      "source": [
        "# Vector Encoding using Product Quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY6ThbML89h6"
      },
      "source": [
        "class ProductIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimension = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels    \n",
        "    def build(self, number_of_partition=8, search_in_x_partitions=2, subvector_size=8):\n",
        "        quantizer = faiss.IndexFlatL2(self.dimension)\n",
        "        self.index = faiss.IndexIVFPQ(quantizer, \n",
        "                                      self.dimension, \n",
        "                                      number_of_partition, \n",
        "                                      search_in_x_partitions, \n",
        "                                      subvector_size)\n",
        "        self.index.train(self.vectors)\n",
        "        self.index.add(self.vectors)\n",
        "        \n",
        "    def query(self, vectors, k=10):\n",
        "        distances, indices = self.index.search(vectors, k) \n",
        "        # I expect only query on one vector thus the slice\n",
        "        return [self.labels[i] for i in indices[0]]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V92EaopX8_cN"
      },
      "source": [
        "index = ProductIndex(data[\"vector\"], data[\"name\"])\n",
        "index.build()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcD3yWjA9A3C",
        "outputId": "7ba0c40d-60e1-4a76-c67d-35bd121bda9d"
      },
      "source": [
        "stack_index = 90\n",
        "stack_vector = data['vector'][stack_index:stack_index+1]\n",
        "print(f\"The most simillar stack to {data['name'][stack_index]} are:\")\n",
        "index.query(stack_vector)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most simillar stack to question_id:90 are:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['question_id:90',\n",
              " 'question_id:63',\n",
              " 'question_id:3579',\n",
              " 'question_id:56',\n",
              " 'question_id:328',\n",
              " 'question_id:19',\n",
              " 'question_id:5031',\n",
              " 'question_id:1292',\n",
              " 'question_id:485',\n",
              " 'question_id:381']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-kw0hDW9bmw",
        "outputId": "42a15f52-5853-4b49-ad6e-1cb8d3a26eba"
      },
      "source": [
        "!pip install annoy\n",
        "import annoy"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: annoy in /usr/local/lib/python3.7/dist-packages (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRSxFHMJIM-Z"
      },
      "source": [
        "# Trees and Graphs using Annoy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e82u0Lyl9DKq"
      },
      "source": [
        "class TreesIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimention = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "    def build(self, number_of_trees=5):\n",
        "        self.index = annoy.AnnoyIndex(self.dimention)\n",
        "        for i, vec in enumerate(self.vectors):\n",
        "            self.index.add_item(i, vec.tolist())\n",
        "        self.index.build(number_of_trees)\n",
        "        \n",
        "    def query(self, vector, k=10):\n",
        "        indices = self.index.get_nns_by_vector(vector.tolist(), k)\n",
        "        return [self.labels[i] for i in indices]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFeQAtcF9FJq",
        "outputId": "a85fc459-4eeb-422e-c714-fa6a77b2b2cb"
      },
      "source": [
        "index = TreesIndex(data[\"vector\"], data[\"name\"])\n",
        "index.build()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: The default argument for metric will be removed in future version of Annoy. Please pass metric='angular' explicitly.\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9_O5nDs9Gtq",
        "outputId": "dc335efc-9130-4cc4-b14a-8c5df63f0c5c"
      },
      "source": [
        "stack_vector, stack_name = data['vector'][90], data['name'][90]\n",
        "simlar_stack_questions = '\\n* '.join(index.query(stack_vector))\n",
        "print(f\"The most similar stack to {stack_name} are:\\n* {simlar_stack_questions}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most similar stack to question_id:90 are:\n",
            "* question_id:90\n",
            "* question_id:88\n",
            "* question_id:36\n",
            "* question_id:82\n",
            "* question_id:3579\n",
            "* question_id:66426\n",
            "* question_id:48\n",
            "* question_id:57585\n",
            "* question_id:96\n",
            "* question_id:370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSLdooij9uQm",
        "outputId": "9b3ae353-17e4-45e4-ce0a-26dc25fa7f16"
      },
      "source": [
        "!pip install nmslib\n",
        "import nmslib"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nmslib in /usr/local/lib/python3.7/dist-packages (2.1.1)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from nmslib) (1.19.5)\n",
            "Requirement already satisfied: pybind11<2.6.2 in /usr/local/lib/python3.7/dist-packages (from nmslib) (2.6.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from nmslib) (5.4.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w68FXUaUIPW1"
      },
      "source": [
        "# HNSW: Hierarchical Navigable Small World Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn8auUU_9ItM"
      },
      "source": [
        "class HNSWIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimention = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels\n",
        "    def build(self):\n",
        "        self.index = nmslib.init(method='hnsw', space='cosinesimil')\n",
        "        self.index.addDataPointBatch(self.vectors)\n",
        "        self.index.createIndex({'post': 2})\n",
        "        \n",
        "    def query(self, vector, k=10):\n",
        "        indices = self.index.knnQuery(vector, k=k)\n",
        "        return [self.labels[i] for i in indices[0]]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDbthVQ09Ket"
      },
      "source": [
        "index = HNSWIndex(data[\"vector\"], data[\"name\"])\n",
        "index.build()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4cu-Uo_9L_c",
        "outputId": "a59fd46a-1514-4fb0-f354-80fff30b425b"
      },
      "source": [
        "stack_vector, stack_name = data['vector'][90], data['name'][90]\n",
        "simlar_stack_questions = '\\n* '.join(index.query(stack_vector))\n",
        "print(f\"The most similar stack to {stack_name} are:\\n* {simlar_stack_questions}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most similar stack to question_id:90 are:\n",
            "* question_id:90\n",
            "* question_id:88\n",
            "* question_id:67247\n",
            "* question_id:3\n",
            "* question_id:36\n",
            "* question_id:159\n",
            "* question_id:121\n",
            "* question_id:82\n",
            "* question_id:86\n",
            "* question_id:11\n"
          ]
        }
      ]
    }
  ]
}